{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72bdb56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Modules\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Imported Modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b32c825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\conno\\OneDrive\\University Study\\Honours Thesis\\cnolan-thesis\n",
      "Set WD: Done\n"
     ]
    }
   ],
   "source": [
    "\"SET THE WORKING DIRECTORY BELOW TO THE LOCATION OF DATA FILES\"\n",
    "\n",
    "working_directory = 'C:/Users/conno/OneDrive/University Study/Honours Thesis/cnolan-thesis' #set location using back slashes\n",
    "\n",
    "os.chdir(working_directory)\n",
    "\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            output_path = os.makedirs(directory)\n",
    "            print(output_path)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "        \n",
    "\n",
    "# Folder where outputs will be saved (by default a folder within the working directory) \n",
    "createFolder('./output/') \n",
    "output_path = working_directory +'./output/'\n",
    "\n",
    "print('Set WD: Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48789c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCarbon premium and risk factors\\n\\nReplication of Table 10: Can the carbon premium be explained by risk factors?\\n\\na 1 ,t = c 0 + c F t + ε t ,\\n\\nTime series variables:\\n\\nα = monthly carbon premium estimated in cross-sectional returns regression\\n\\nMKTRF is the monthly return on the value-weighted stock market net of the risk-free rate\\nHML is the monthly return on the portfolio long value stocks and short growth stocks\\nSMB is the monthly return on the portfolio long small-cap stocks and short, large-cap stocks\\nMOM is the monthly return on the portfolio long 12-month stock winners and short 12-month past losers\\nCMA is the monthly return of a portfolio that is long on conservative investment stocks and short on aggressive investment stocks\\nBAB is the monthly return of a portfolio that is long on low-beta stocks and short on high-beta stocks\\nLIQ is the liquidity factor of Pastor and Stambaugh\\nNET ISSUANCE is the monthly return of a portfolio that is long on high-net-issuance stocks and short on low-net-issuance stocks. Net issuance for year t is the change in the natural log of split-adjusted shares outstanding from the fiscal yearend in t -2 to the fiscal yearend in t -1\\nIDIO VOL is the monthly return of a portfolio that is long on low idiosyncratic volatility stocks and short on high idiosyncratic volatility stocks.\\n\\n   \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Carbon premium and risk factors\n",
    "\n",
    "Replication of Table 10: Can the carbon premium be explained by risk factors?\n",
    "\n",
    "a 1 ,t = c 0 + c F t + ε t ,\n",
    "\n",
    "Time series variables:\n",
    "\n",
    "α = monthly carbon premium estimated in cross-sectional returns regression\n",
    "\n",
    "MKTRF is the monthly return on the value-weighted stock market net of the risk-free rate\n",
    "HML is the monthly return on the portfolio long value stocks and short growth stocks\n",
    "SMB is the monthly return on the portfolio long small-cap stocks and short, large-cap stocks\n",
    "MOM is the monthly return on the portfolio long 12-month stock winners and short 12-month past losers\n",
    "CMA is the monthly return of a portfolio that is long on conservative investment stocks and short on aggressive investment stocks\n",
    "BAB is the monthly return of a portfolio that is long on low-beta stocks and short on high-beta stocks\n",
    "LIQ is the liquidity factor of Pastor and Stambaugh\n",
    "NET ISSUANCE is the monthly return of a portfolio that is long on high-net-issuance stocks and short on low-net-issuance stocks. Net issuance for year t is the change in the natural log of split-adjusted shares outstanding from the fiscal yearend in t -2 to the fiscal yearend in t -1\n",
    "IDIO VOL is the monthly return of a portfolio that is long on low idiosyncratic volatility stocks and short on high idiosyncratic volatility stocks.\n",
    "\n",
    "   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79009062",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\AppData\\Local\\Temp\\ipykernel_3924\\1082030742.py\"\u001b[0m, line \u001b[0;32m2\u001b[0m, in \u001b[0;35m<cell line: 2>\u001b[0m\n    csr_carbon_premium = pd.read_csv ('https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/output/csr_carbon_premium.csv')\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\site-packages\\pandas\\util\\_decorators.py\"\u001b[0m, line \u001b[0;32m311\u001b[0m, in \u001b[0;35mwrapper\u001b[0m\n    return func(*args, **kwargs)\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\"\u001b[0m, line \u001b[0;32m678\u001b[0m, in \u001b[0;35mread_csv\u001b[0m\n    return _read(filepath_or_buffer, kwds)\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\"\u001b[0m, line \u001b[0;32m575\u001b[0m, in \u001b[0;35m_read\u001b[0m\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\"\u001b[0m, line \u001b[0;32m932\u001b[0m, in \u001b[0;35m__init__\u001b[0m\n    self._engine = self._make_engine(f, self.engine)\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\"\u001b[0m, line \u001b[0;32m1216\u001b[0m, in \u001b[0;35m_make_engine\u001b[0m\n    self.handles = get_handle(  # type: ignore[call-overload]\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\site-packages\\pandas\\io\\common.py\"\u001b[0m, line \u001b[0;32m667\u001b[0m, in \u001b[0;35mget_handle\u001b[0m\n    ioargs = _get_filepath_or_buffer(\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\site-packages\\pandas\\io\\common.py\"\u001b[0m, line \u001b[0;32m336\u001b[0m, in \u001b[0;35m_get_filepath_or_buffer\u001b[0m\n    with urlopen(req_info) as req:\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\site-packages\\pandas\\io\\common.py\"\u001b[0m, line \u001b[0;32m236\u001b[0m, in \u001b[0;35murlopen\u001b[0m\n    return urllib.request.urlopen(*args, **kwargs)\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\urllib\\request.py\"\u001b[0m, line \u001b[0;32m216\u001b[0m, in \u001b[0;35murlopen\u001b[0m\n    return opener.open(url, data, timeout)\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\urllib\\request.py\"\u001b[0m, line \u001b[0;32m525\u001b[0m, in \u001b[0;35mopen\u001b[0m\n    response = meth(req, response)\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\urllib\\request.py\"\u001b[0m, line \u001b[0;32m634\u001b[0m, in \u001b[0;35mhttp_response\u001b[0m\n    response = self.parent.error(\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\urllib\\request.py\"\u001b[0m, line \u001b[0;32m563\u001b[0m, in \u001b[0;35merror\u001b[0m\n    return self._call_chain(*args)\n",
      "  File \u001b[0;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\urllib\\request.py\"\u001b[0m, line \u001b[0;32m496\u001b[0m, in \u001b[0;35m_call_chain\u001b[0m\n    result = func(*args)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\conno\\anaconda3\\envs\\spyder-env\\lib\\urllib\\request.py\"\u001b[1;36m, line \u001b[1;32m643\u001b[1;36m, in \u001b[1;35mhttp_error_default\u001b[1;36m\u001b[0m\n\u001b[1;33m    raise HTTPError(req.full_url, code, msg, hdrs, fp)\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m\u001b[1;31m:\u001b[0m Not Found\n"
     ]
    }
   ],
   "source": [
    "\"import data\"\n",
    "csr_carbon_premium = pd.read_csv ('https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/output/csr_carbon_premium.csv')\n",
    "fama_french_5_factors = pd.read_csv ('https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/data/Asia_Pacific_ex_Japan_5_Factors.csv')\n",
    "fama_french_mom_factor = pd.read_csv ('https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/data/Asia_Pacific_ex_Japan_MOM_Factor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Filter fama-french factors by the sample period\"\n",
    "fama_french_5_factors = fama_french_5_factors[(fama_french_5_factors['year-month'] >= 200807) & (fama_french_5_factors['year-month'] <= 202106)]\n",
    "fama_french_mom_factor = fama_french_mom_factor[(fama_french_mom_factor['year-month'] >= 200807) & (fama_french_mom_factor['year-month'] <= 202106)]\n",
    "\n",
    "carbon_premium_risk_factors_vars = pd.merge(csr_carbon_premium[['year','month','pmc']], fama_french_5_factors[['year-month','year', 'month', 'MKT-RF', 'SMB', 'HML']], how='left', on=['year','month'])\n",
    "carbon_premium_risk_factors_vars = pd.merge(carbon_premium_risk_factors_vars, fama_french_mom_factor[['year', 'month', 'WML']], how='left', on=['year','month'])\n",
    "#carbon_premium_risk_factors_vars = pd.merge(carbon_premium_risk_factors_vars, cross_sectional_returns[['ticker_year_month','ticker','year','month','ret']], how='right', on=['year','month'])\n",
    "\n",
    "obs_before = len(carbon_premium_risk_factors_vars)\n",
    "\n",
    "carbon_premium_risk_factors_vars = carbon_premium_risk_factors_vars.dropna(subset=['ret', 'MKT-RF', 'SMB', 'HML', 'WML', 'pmc']).reset_index(drop=True)\n",
    "\n",
    "obs_after = len(carbon_premium_risk_factors_vars)\n",
    "obs_dropped = (obs_before - obs_after)\n",
    "print('dropna(variables): ' + str(obs_dropped))\n",
    "\n",
    "carbon_premium_risk_factors_vars = carbon_premium_risk_factors_vars[['ticker_year_month','ticker', 'year-month', 'year','month', 'ret', 'MKT-RF', 'SMB', 'HML', 'WML', 'pmc']]\n",
    "\n",
    "\n",
    "\"Save carbon_beta_log_scope1_vars\"\n",
    "output_filename = 'carbon_premium_risk_factors_vars.csv'\n",
    "outputname = output_path + output_filename\n",
    "carbon_premium_risk_factors_vars.to_csv(outputname, mode='w', index=False)\n",
    "print(\"Exported File: \" + outputname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Notebook Finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
