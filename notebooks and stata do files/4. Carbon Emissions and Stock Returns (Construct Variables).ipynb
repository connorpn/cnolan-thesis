{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd9333d",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a29ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a5c0b",
   "metadata": {},
   "source": [
    "# Set Working Directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e6f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"SET THE WORKING DIRECTORY BELOW TO THE LOCATION OF DATA FILES\"\n",
    "\n",
    "working_directory = 'C:/Users/conno/OneDrive/University Study/Honours Thesis/cnolan-thesis' #set location using back slashes\n",
    "\n",
    "os.chdir(working_directory)\n",
    "\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            output_path = os.makedirs(directory)\n",
    "            print(output_path)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "        \n",
    "\n",
    "# Folder where outputs will be saved (by default a folder within the working directory) \n",
    "createFolder('./output/') \n",
    "output_path = working_directory +'./output/'\n",
    "\n",
    "print('Set WD: Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11f79a",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90edb4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nger_data_matched = pd.read_csv('https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/output/nger_data_matched.csv',encoding = \"ISO-8859-1\")\n",
    "ms_data = pd.read_csv ('https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/output/ms_data.csv', encoding='latin1')\n",
    "\n",
    "price_data = pd.read_csv('https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/data/ds_matched_dailyprice.csv')\n",
    "marketcap = pd.read_csv('https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/data/ds_marketcap.csv')\n",
    "beta = pd.read_csv('https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/data/ds_beta.csv')\n",
    "industry = pd.read_csv ('https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/data/ds_ticker_industry.csv')\n",
    "\n",
    "matched_tickers = pd.read_csv(\"https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/output/matched_tickers_list.csv\")\n",
    "matched_tickers_list = matched_tickers['ticker'].tolist()\n",
    "\n",
    "\"Add Ticker Year ID\"\n",
    "nger_data_matched['year'] = nger_data_matched['year'].astype(str)\n",
    "ms_data['year'] = ms_data['year'].astype(str)\n",
    "\n",
    "nger_data_matched['ticker_year'] = nger_data_matched['ticker'] + '_' + nger_data_matched['year']\n",
    "ms_data['ticker_year'] = ms_data['ticker'] + '_' + ms_data['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d05dae",
   "metadata": {},
   "source": [
    "# Construct Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3fa752",
   "metadata": {},
   "source": [
    "## Dependent Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291827b8",
   "metadata": {},
   "source": [
    "### RET "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb201f",
   "metadata": {},
   "source": [
    "RET i,t<br>\n",
    "Mesures the stock return of company i in month t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7129b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format date\n",
    "price_data['Date'] = pd.to_datetime(price_data['Date'], format='%d/%m/%Y')\n",
    "price_data.set_index('Date',inplace=True)\n",
    "\n",
    "\n",
    "#calculate monthly return\n",
    "monthly_price_data = price_data.resample('M').ffill()\n",
    "monthly_price_change = monthly_price_data / monthly_price_data.shift(1) - 1 \n",
    "columns = ['29M', 'ARI', 'ABB1', 'ABC', 'ABY1', 'AIS', 'AGL', 'ALK', 'AQZ', 'AMP', 'ALD', 'ALG', 'AOE', 'AHY', 'AIO', 'AGO', 'AMI', 'AZJ', 'AST', 'AQC', 'AHG', 'BPT', 'BGA', 'BHP', 'BIN', 'BSL', 'BLD', 'B2Y', 'BKN', 'BKW', 'BRS', 'CAA', 'CBH1', 'CEY', 'CTP', 'CHC', 'CIM', 'CWY', 'CCL', 'CGJ', 'CBA', 'CWN', 'CSL', 'CSR', 'CDU', 'CEP', 'CER', 'CRG', 'DCN', 'DJS', 'DXS', 'DOW', 'APE', 'ENV1', 'EPW', 'EVT', 'EVN', 'ESG', 'ELD', 'ENE1', 'FMG', 'FGL1', 'FXJ', 'FLX1', 'FML', 'GCY', 'GFF', 'GNC', 'GRR', 'GCL', 'GNS', 'HVN', 'HSO', 'HGO', 'HRL', 'IGO', 'ILU', 'IMA', 'IPL', 'ING', 'IVA', 'IGR', 'IPG2', 'JBH', 'KZL', 'LLC', 'LAU', 'AEJ']\n",
    "for i in columns:\n",
    "    monthly_price_change[i] = monthly_price_change[i].replace(0, np.nan)\n",
    "\n",
    "#reformat to multi column (year, month) index\n",
    "monthly_price_change = monthly_price_change.reset_index()\n",
    "monthly_price_change['year'] = monthly_price_change['Date'].dt.strftime('%Y')\n",
    "monthly_price_change['month'] = monthly_price_change['Date'].dt.strftime('%m')\n",
    "\n",
    "#reshape df into time series format\n",
    "monthly_price_change = pd.melt(monthly_price_change, id_vars = ['Date', 'year', 'month'], value_vars= ['29M', 'ARI', 'ABB1', 'ABC', 'ABY1', 'AIS', 'AGL', 'ALK', 'AQZ', 'AMP', 'ALD', 'ALG', 'AOE', 'AHY', 'AIO', 'AGO', 'AMI', 'AZJ', 'AST', 'AQC', 'AHG', 'BPT', 'BGA', 'BHP', 'BIN', 'BSL', 'BLD', 'B2Y', 'BKN', 'BKW', 'BRS', 'CAA', 'CBH1', 'CEY', 'CTP', 'CHC', 'CIM', 'CWY', 'CCL', 'CGJ', 'CBA', 'CWN', 'CSL', 'CSR', 'CDU', 'CEP', 'CER', 'CRG', 'DCN', 'DJS', 'DXS', 'DOW', 'APE', 'ENV1', 'EPW', 'EVT', 'EVN', 'ESG', 'ELD', 'ENE1', 'FMG', 'FGL1', 'FXJ', 'FLX1', 'FML', 'GCY', 'GFF', 'GNC', 'GRR', 'GCL', 'GNS', 'HVN', 'HSO', 'HGO', 'HRL', 'IGO', 'ILU', 'IMA', 'IPL', 'ING', 'IVA', 'IGR', 'IPG2', 'JBH', 'KZL', 'LLC', 'LAU', 'AEJ'], var_name = 'ticker', value_name='monthly_return',col_level=None)\n",
    "monthly_price_change['monthly_return'] = monthly_price_change.monthly_return.astype(float)\n",
    "\n",
    "\n",
    "ret = monthly_price_change[['Date','year','month','ticker','monthly_return']]\n",
    "ret = ret.rename(columns={'monthly_return':'ret'})\n",
    "ret = ret.reset_index(drop=True)\n",
    "ret['ticker_year_month'] = ret['ticker'] + '_' + ret['year'] + '_' + ret ['month']\n",
    "\n",
    "ret_merge = ret[['ticker_year_month','ticker','year','month','ret']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9a469",
   "metadata": {},
   "source": [
    "## Dependent Variables (Carbon Emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_vars = nger_data_matched\n",
    "independent_vars = pd.merge(independent_vars, ms_data[['ticker_year','revenue']], how='left', on=['ticker_year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe7cda",
   "metadata": {},
   "source": [
    "###  Log (Scope 1, Scope 2, Total Emissions, Energy Consumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c8ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log scope1, scope2, total_emissions, and energy consumption\n",
    "independent_vars['log_scope1'] = np.log(independent_vars['scope1'])\n",
    "independent_vars['log_scope2'] = np.log(independent_vars['scope2'])\n",
    "independent_vars['log_total_emissions'] = np.log(independent_vars['total_emissions'])\n",
    "independent_vars['log_energy_consumption'] = np.log(independent_vars['energy_consumption'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea08528",
   "metadata": {},
   "source": [
    "###  Year by year change in emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf74668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clone each unique company for each observation year (2009-2021)\n",
    "firms_2009 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2009'})\n",
    "firms_2010 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2010'})\n",
    "firms_2011 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2011'})\n",
    "firms_2012 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2012'})\n",
    "firms_2013 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2013'})\n",
    "firms_2014 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2014'})\n",
    "firms_2015 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2015'})\n",
    "firms_2016 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2016'})\n",
    "firms_2017 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2017'})\n",
    "firms_2018 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2018'})\n",
    "firms_2019 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2019'})\n",
    "firms_2020 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2020'})\n",
    "firms_2021 = pd.DataFrame({'ticker':matched_tickers_list, 'year': '2021'})\n",
    "\n",
    "#create dataframe to add all cloned firm years\n",
    "firms_allyears = pd.DataFrame(columns = ['ticker', 'year'])\n",
    "\n",
    "#add all clone firm year dataframes to a list\n",
    "firm_years_list = [firms_2009, firms_2010, firms_2011, firms_2012, firms_2013, firms_2014, firms_2015, firms_2016, firms_2017, firms_2018, firms_2019, firms_2020, firms_2021]\n",
    "\n",
    "#concatenate dataframes\n",
    "firms_allyears = pd.concat(firm_years_list)\n",
    "\n",
    "firms_allyears['ticker_year'] = firms_allyears['ticker'] + '_' + firms_allyears['year']\n",
    "\n",
    "#create dummy level index\n",
    "independent_vars[\"dummy_index\"] = independent_vars[\"dummy_index\"] = 1\n",
    "firms_allyears['dummy_index'] = firms_allyears['dummy_index'] = 2\n",
    "\n",
    "#concenate cloned firm years with main data file\n",
    "independent_vars = pd.concat([independent_vars, firms_allyears]).reset_index(drop=True)\n",
    "\n",
    "#sort dataframe by corporation name and year\n",
    "independent_vars = independent_vars.sort_values(by=['ticker', 'year','ticker']).reset_index(drop=True)\n",
    "\n",
    "#drop duplicates keeping first row (main  data file) as by dummy_index sorting\n",
    "independent_vars = independent_vars.drop_duplicates(['ticker', 'year','ticker'], keep='first').reset_index(drop=True)\n",
    "\n",
    "\n",
    "independent_vars['year'] =  pd.to_datetime(independent_vars['year'], format='%Y').dt.to_period(\"Y\")\n",
    "\n",
    "\n",
    "#calculate yearly change in emissions by corporation for scope1, scope2, total_emissions, and energy consumption\n",
    "independent_vars['change_scope1'] = independent_vars.groupby(['ticker'])['scope1'].diff()\n",
    "independent_vars['change_scope2'] = independent_vars.groupby(['ticker'])['scope2'].diff()\n",
    "independent_vars['change_total_emissions'] = independent_vars.groupby(['ticker'])['total_emissions'].diff()\n",
    "independent_vars['change_energy_consumption'] = independent_vars.groupby(['ticker'])['energy_consumption'].diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f247be1",
   "metadata": {},
   "source": [
    "### Intensity (Emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c740ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## int = (tons CO 2 e/AUD m.)\n",
    "independent_vars['revenue(m)'] = independent_vars['revenue'] / 1000000\n",
    "independent_vars['scope1_int'] = independent_vars['scope1'] /  independent_vars['revenue(m)']\n",
    "independent_vars['scope2_int'] = independent_vars['scope2'] /  independent_vars['revenue(m)']\n",
    "independent_vars['total_emissions_int'] = independent_vars['total_emissions'] /  independent_vars['revenue(m)']\n",
    "independent_vars['energy_consumption_int'] = independent_vars['energy_consumption'] / independent_vars['revenue(m)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740f082",
   "metadata": {},
   "source": [
    "### Independent Variables: Drop Blank Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_vars = independent_vars.dropna(subset=['scope1', 'scope2', 'energy_consumption', 'total_emissions'],how='any').reset_index(drop=True)\n",
    "independent_vars = independent_vars[['year', 'ticker', 'ticker_year', 'log_scope1', 'log_scope2', 'log_total_emissions', 'log_energy_consumption', 'change_scope1', 'change_scope2', 'change_total_emissions', 'change_energy_consumption', 'scope1_int', 'scope2_int', 'total_emissions_int', 'energy_consumption_int']]\n",
    "\n",
    "independent_vars_merge = independent_vars[['ticker_year','year','ticker','log_scope1', 'log_scope2', 'log_total_emissions', 'log_energy_consumption', 'change_scope1', 'change_scope2', 'change_total_emissions', 'change_energy_consumption', 'scope1_int', 'scope2_int', 'total_emissions_int', 'energy_consumption_int']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61256c79",
   "metadata": {},
   "source": [
    "## Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_vars = ms_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ed2e80",
   "metadata": {},
   "source": [
    "### log size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8369a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_vars['logsize'] = np.log(control_vars['marketcap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff48a68",
   "metadata": {},
   "source": [
    "### B/M (book to market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a84f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_vars['bm'] = (control_vars['assets'] - control_vars['liabilities']) / control_vars['marketcap']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eff1d0",
   "metadata": {},
   "source": [
    "### Leverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab665aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_vars['totaldebt'] = control_vars.stdebt.fillna(0) + control_vars.ltdebt.fillna(0) #calculate total debt, skipping nan values (this means total debt can be constructed from ltdebt, stdebt, or both)\n",
    "control_vars['leverage'] = control_vars.totaldebt / control_vars.assets #calculate leverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b746b8c",
   "metadata": {},
   "source": [
    "### MOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a0e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mom = monthly_price_change.reset_index(drop=True)\n",
    "mom = mom.set_index('Date')\n",
    "mom = mom.to_period(freq=\"M\")\n",
    "mom['lag_monthly_return'] = mom.monthly_return.shift(1)\n",
    "mom['mom'] = mom.lag_monthly_return.rolling(12).mean()\n",
    "mom = mom.reset_index(drop=True)\n",
    "mom['ticker_year_month'] = mom['ticker'] + '_' + mom['year'] + '_' + mom['month']\n",
    "mom_merge = mom[['ticker_year_month','mom']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1b8344",
   "metadata": {},
   "source": [
    "### INVEST/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590dc98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_vars['investa'] = control_vars.capex / control_vars.assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc8ab8f",
   "metadata": {},
   "source": [
    "### ROE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163995a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#control_vars['roe'] #already have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b9605",
   "metadata": {},
   "source": [
    "### HHI (ignore: unable to source firm revenues by busniess segement - limitation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371534ae",
   "metadata": {},
   "source": [
    "### LOGPPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_vars['logppe'] = np.log(control_vars['ppe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c527e1",
   "metadata": {},
   "source": [
    "### BETA<br>\n",
    "BETA i,t <br>\n",
    "Is the market beta of firm i in year t, calculated over the one year period using daily data<br>\n",
    "<br>\n",
    "Data is year from 01/07/2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ade65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = beta.drop('CEP', axis = 1)\n",
    "beta['year'] = pd.to_datetime(beta['year'], format='%Y')\n",
    "beta['year'] = beta['year'].dt.strftime('%Y')\n",
    "beta = beta.set_index('year')\n",
    "beta_cols = list(beta)\n",
    "beta = beta.reset_index()\n",
    "beta = pd.melt(beta, id_vars = ['year'], value_vars = beta_cols, var_name = 'ticker', value_name='beta',col_level=None)\n",
    "beta['ticker_year'] = beta['ticker'] + '_' + beta['year']\n",
    "beta_merge = beta[['ticker_year','beta']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c3af4",
   "metadata": {},
   "source": [
    "### VOLAT<br>\n",
    "VOLAT i,t <br>\n",
    "Is the standard devation of returns based on the past 12 months of monthly returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec69ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "volat = price_data\n",
    "volat = volat.drop('CEP', axis = 1)\n",
    "volat = volat.resample('M').ffill()\n",
    "volat_cols = list(volat)\n",
    "volat = volat.reset_index()\n",
    "volat = pd.melt(volat, id_vars = ['Date'], value_vars = volat_cols, var_name = 'ticker', value_name='price',col_level=None)\n",
    "volat['price'] = volat.price.astype(float)\n",
    "volat = volat.set_index('Date').sort_values('ticker')\n",
    "volat['pct'] = volat.groupby('ticker')['price'].pct_change()\n",
    "volat['volat'] = volat['pct'].rolling(12).std()\n",
    "volat = volat.reset_index()\n",
    "volat['year'] = volat['Date'].dt.strftime('%Y')\n",
    "volat['month'] = volat['Date'].dt.strftime('%m')\n",
    "volat['ticker_year_month'] = volat['ticker'] + '_' + volat['year'] + '_' + volat['month']\n",
    "\n",
    "volat_merge = volat[['ticker_year_month','volat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11351052",
   "metadata": {},
   "source": [
    "### SALESGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b83167",
   "metadata": {},
   "outputs": [],
   "source": [
    "marketcap = marketcap.dropna(how='all')\n",
    "marketcap = marketcap.drop('CEP', axis = 1)\n",
    "marketcap['Date'] = pd.to_datetime(marketcap['Date'], format='%d/%m/%Y')\n",
    "marketcap = marketcap.set_index('Date')\n",
    "marketcap_cols = list(marketcap)\n",
    "marketcap = marketcap.reset_index()\n",
    "marketcap = pd.melt(marketcap, id_vars = ['Date'], value_vars = marketcap_cols, var_name = 'ticker', value_name = 'marketcap', col_level = None)\n",
    "marketcap['year'] = marketcap['Date'].dt.strftime('%Y')\n",
    "marketcap['marketcap'] = marketcap['marketcap'].astype(float)\n",
    "marketcap['marketcap'] = marketcap['marketcap'] * 1000000\n",
    "marketcap['marketcap_lag'] = marketcap['marketcap'].shift(1)\n",
    "marketcap['year'] = marketcap['Date'].dt.strftime('%Y')\n",
    "marketcap['month'] = marketcap['Date'].dt.strftime('%m')\n",
    "marketcap['ticker_year'] = marketcap['ticker'] + '_' + marketcap['year'] \n",
    "marketcap['ticker_year_month'] = marketcap['ticker'] + '_' + marketcap['year'] + '_' + marketcap['month']\n",
    "\n",
    "revenue_change = ms_data[['ticker_year','year','ticker','revenue']]\n",
    "revenue_change = revenue_change.sort_values(by=['ticker', 'year']) #sort dataframe by ticker and year\n",
    "revenue_change['revenue_change'] = revenue_change.groupby(['ticker'])['revenue'].diff() #calculate yearly change in revenue by firm\n",
    "\n",
    "\n",
    "salesgr = pd.merge(marketcap, revenue_change, how='left', on=['ticker_year'])\n",
    "\n",
    "salesgr['salesgr'] = salesgr.revenue_change / salesgr.marketcap #salesgr = change in annual revenue normailzed by marketcap\n",
    "\n",
    "salesgr_merge = salesgr[['ticker_year_month','salesgr']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c732f1",
   "metadata": {},
   "source": [
    "### EPSGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2493de",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_change = ms_data[['ticker_year','year','ticker','eps']]\n",
    "eps_change = eps_change.sort_values(by=['ticker', 'year']) #sort dataframe by ticker and year\n",
    "eps_change['eps'] = eps_change['eps'].astype(float)\n",
    "eps_change['eps_change'] = eps_change.groupby(['ticker'])['eps'].diff() #calculate yearly change in eps by firm\n",
    "\n",
    "\n",
    "monthly_price = monthly_price_data\n",
    "monthly_price_cols = list(monthly_price)\n",
    "monthly_price = monthly_price.reset_index()\n",
    "monthly_price = pd.melt(monthly_price, id_vars = ['Date'], value_vars= monthly_price_cols, var_name = 'ticker', value_name='eom_price',col_level=None)\n",
    "monthly_price['eom_price'] = monthly_price['eom_price'].astype(float)\n",
    "monthly_price['year'] = monthly_price['Date'].dt.strftime('%Y')\n",
    "monthly_price['month'] = monthly_price['Date'].dt.strftime('%m')\n",
    "monthly_price['ticker_year'] = monthly_price['ticker'] + '_' + monthly_price['year'] \n",
    "monthly_price['ticker_year_month'] = monthly_price['ticker'] + '_' + monthly_price['year'] + '_' + monthly_price['month']\n",
    "\n",
    "epsgr = pd.merge(monthly_price, eps_change[['ticker_year', 'eps', 'eps_change']], how = 'left', on =['ticker_year'])\n",
    "epsgr['epsgr'] = epsgr.eps_change / epsgr.eom_price\n",
    "\n",
    "epsgr_merge = epsgr[['ticker_year_month', 'epsgr']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81746e5",
   "metadata": {},
   "source": [
    "# Merge Variables (t = month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret_merge\n",
    "# mom_merge\n",
    "# volat_merge\n",
    "# salesgr_merge\n",
    "# epsgr_merge\n",
    "\n",
    "monthly_merge = pd.merge(ret_merge, mom_merge, on=['ticker_year_month'], how = 'outer')\n",
    "monthly_merge = pd.merge(monthly_merge, volat_merge, on=['ticker_year_month'], how = 'outer')\n",
    "monthly_merge = pd.merge(monthly_merge, salesgr_merge, on=['ticker_year_month'], how = 'outer')\n",
    "monthly_merge = pd.merge(monthly_merge, epsgr_merge, on=['ticker_year_month'], how = 'outer')\n",
    "\n",
    "monthly_merge['ticker_year'] = monthly_merge['ticker'] + '_' + monthly_merge['year']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1b715",
   "metadata": {},
   "source": [
    "# Merge Variables (t = year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e97c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent_vars_merge\n",
    "# logsize_merge\n",
    "# bm_merge\n",
    "# leverage_merge\n",
    "# investa_merge\n",
    "# roe_merge\n",
    "# logppe_merge\n",
    "# beta_merge\n",
    "\n",
    "\"Merge on the yearly emissions variables\"\n",
    "yearly_merge = pd.merge(independent_vars_merge, control_vars[['ticker_year','logsize','bm','leverage','investa','roe','logppe']], on=['ticker_year'], how = 'outer')\n",
    "yearly_merge = pd.merge(yearly_merge, beta_merge, on=['ticker_year'], how = 'outer')\n",
    "\n",
    "\n",
    "\"Explode yearly data so that the yearly observation is duplicated for each month 01-12\"\n",
    "\n",
    "months_list_df = pd.DataFrame({'month':[['01','02','03','04','05','06','07','08','09','10','11','12']]})\n",
    "len_yearly_merge = len(yearly_merge)\n",
    "months_list_df = pd.concat([months_list_df]*len_yearly_merge, ignore_index=True)\n",
    "yearly_merge = yearly_merge.join(months_list_df)\n",
    "\n",
    "yearly_merge = yearly_merge.explode('month')\n",
    "#.reset_index(drop=True)\n",
    "yearly_merge['ticker_year_month'] = yearly_merge['ticker_year'] + '_' + yearly_merge['month']\n",
    "yearly_merge = yearly_merge.sort_values(by=['ticker_year_month']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0055c3",
   "metadata": {},
   "source": [
    "# Merge Monthly and Yearly Variables + add industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba592326",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cross_sectional_returns = pd.merge(monthly_merge[['ticker_year_month', 'ticker', 'year', 'month', 'ret', 'mom', 'volat', 'salesgr', 'epsgr']],\n",
    "                      yearly_merge[['ticker_year_month','log_scope1', 'log_scope2', 'log_total_emissions', 'log_energy_consumption', 'change_scope1', 'change_scope2', 'change_total_emissions', 'change_energy_consumption', 'scope1_int', 'scope2_int', 'total_emissions_int', 'energy_consumption_int', 'logsize', 'bm', 'leverage', 'investa', 'roe', 'logppe', 'beta']],\n",
    "                      how = 'outer',\n",
    "                      on=['ticker_year_month'])\n",
    "\n",
    "data_cross_sectional_returns= pd.merge(data_cross_sectional_returns, industry, on=['ticker'], how='left')\n",
    "\n",
    "data_cross_sectional_returns = data_cross_sectional_returns.reindex(columns=['ticker_year_month', 'ticker', 'industry', 'year', 'month', 'ret', 'log_scope1', 'log_scope2', 'log_total_emissions', 'log_energy_consumption', 'change_scope1', 'change_scope2', 'change_total_emissions', 'change_energy_consumption', 'scope1_int', 'scope2_int', 'total_emissions_int', 'energy_consumption_int', 'logsize', 'bm', 'leverage', 'mom', 'investa', 'roe', 'logppe', 'beta', 'volat', 'salesgr', 'epsgr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545fe16",
   "metadata": {},
   "source": [
    "# Drop Missing Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea79340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cross_sectional_returns = data_cross_sectional_returns.dropna(how = 'any', subset=['ret', 'logsize', 'bm', 'leverage', 'mom', 'investa', 'roe', 'logppe', 'beta', 'volat', 'salesgr', 'epsgr'])\n",
    "data_cross_sectional_returns = data_cross_sectional_returns.dropna(how = 'all', subset=['log_scope1', 'log_scope2', 'log_total_emissions', 'log_energy_consumption', 'change_scope1', 'change_scope2', 'change_total_emissions', 'change_energy_consumption', 'scope1_int', 'scope2_int', 'total_emissions_int', 'energy_consumption_int'])\n",
    "\n",
    "obs_prev = len(data_cross_sectional_returns)\n",
    "data_cross_sectional_returns = data_cross_sectional_returns.dropna(subset=['industry'])\n",
    "obs_after = len(data_cross_sectional_returns)\n",
    "print('obs dropped from industry dropna: '+ str(obs_prev-obs_after))\n",
    "\n",
    "data_cross_sectional_returns = data_cross_sectional_returns.sort_values(by=['year','month','ticker']).reset_index(drop=True)\n",
    "\n",
    "data_cross_sectional_returns['yearmonth'] = data_cross_sectional_returns['year'].astype(str) + data_cross_sectional_returns['month'].astype(str)\n",
    "data_cross_sectional_returns['yearmonth'] = data_cross_sectional_returns['yearmonth'].astype(int)\n",
    "\n",
    "\"Save Cabron Emissions and Stock Returns Data\"\n",
    "output_filename = 'carbon_emissions_stock_returns_vars.csv'\n",
    "outputname = output_path + output_filename\n",
    "data_cross_sectional_returns.to_csv(outputname, mode='w', index=False)\n",
    "print(\"Exported File: \" + outputname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d931ea4",
   "metadata": {},
   "source": [
    "# Display Cross Sectional Returns Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55776c8",
   "metadata": {},
   "source": [
    "## >Display Observations with No Missing Dependent, Independent, & Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d59fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Number of Observations:')\n",
    "print (len(data_cross_sectional_returns))\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(data_cross_sectional_returns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f00321",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Notebook Finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
