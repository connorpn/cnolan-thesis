{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96cd4ed4",
   "metadata": {},
   "source": [
    "This notebook matches unique nger firm names to publically listed firms during the sample pariod and appends the corresponding ticker. This allows for nger data to be merged with firm data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ce7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abcf55a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\conno\\OneDrive\\University Study\\Honours Thesis\\cnolan-thesis\n",
      "Set WD: Done\n"
     ]
    }
   ],
   "source": [
    "\"SET THE WORKING DIRECTORY BELOW TO THE LOCATION OF DATA FILES\"\n",
    "\n",
    "working_directory = 'C:/Users/conno/OneDrive/University Study/Honours Thesis/cnolan-thesis' #set location using back slashes\n",
    "\n",
    "os.chdir(working_directory)\n",
    "\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            output_path = os.makedirs(directory)\n",
    "            print(output_path)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "        \n",
    "\n",
    "# Folder where outputs will be saved (by default a folder within the working directory) \n",
    "createFolder('./output/') \n",
    "output_path = working_directory +'./output/'\n",
    "\n",
    "print('Set WD: Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af239c90",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3397398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS DATA IS COLLATED AND PROCESSED FROM NOTEBOOK: 1. Collate Data\n",
    "nger_data = pd.read_csv('https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/output/nger_data.csv',encoding = \"ISO-8859-1\")\n",
    "ms_data = pd.read_csv ('https://raw.githubusercontent.com/connorpn/cnolan-thesis/main/output/ms_data.csv', encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd44387d",
   "metadata": {},
   "source": [
    "# Fuzzy Match NGER and Morningstar Firm Names (This Process Takes A Long Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_firms = ms_data[['ticker', 'morningstar_name']]\n",
    "ms_firms = ms_firms.drop_duplicates(subset=['morningstar_name'])\n",
    "\n",
    "ms_firms_list = []\n",
    "ms_firms_list = ms_data['morningstar_name'].unique().tolist()\n",
    "\n",
    "nger_firms_list = []\n",
    "nger_firms_list = nger_data['nger_name'].unique().tolist()\n",
    "\n",
    "\n",
    "threshold = 95 #note: in preliminary analysis a threshold of 95 provided matching without mismatching \n",
    "names_response = []\n",
    "for name in nger_firms_list:\n",
    "    resp_match =  process.extractOne(name,ms_firms_list)\n",
    "    if resp_match[1] > threshold:\n",
    "         row = {'nger_name':name,'morningstar_name':resp_match[0], 'match_score':resp_match[1]}\n",
    "         names_response.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e98e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_firms = pd.DataFrame(names_response)\n",
    "\n",
    "matched_firms_tickers = pd.merge(matched_firms[['nger_name', 'morningstar_name', 'match_score']],\n",
    "                            ms_firms[['ticker', 'morningstar_name']],\n",
    "                                          on = ['morningstar_name'],\n",
    "                                          how = 'left')\n",
    "\n",
    "matched_firms_tickers[\"matched\"] = 1\n",
    "matched_firms_tickers = matched_firms_tickers.reindex(columns=['nger_name', 'morningstar_name', 'ticker','matched','match_score'])\n",
    "\n",
    "\"Save Matched Firms File\"\n",
    "output_filename = 'matched_firms_tickers.csv'\n",
    "outputname = output_path + output_filename\n",
    "matched_firms_tickers.to_csv(outputname, mode='w')\n",
    "print(\"Exported File: \" + outputname)\n",
    "\n",
    "#ticker list for datastream series search\n",
    "matched_tickers = matched_firms_tickers['ticker']\n",
    "\n",
    "\"Save Matched Firms List File\"\n",
    "output_filename = 'matched_tickers.csv'\n",
    "outputname = output_path + output_filename\n",
    "matched_tickers.to_csv(outputname, mode='w')\n",
    "print(\"Exported File: \" + outputname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f847377",
   "metadata": {},
   "source": [
    "# Append Matched Data to NGER Data and Filter (Matched Only NGER Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nger_data_matched = pd.merge(nger_data[['year', 'nger_name', 'scope1', 'scope2', 'energy_consumption', 'total_emissions']], matched_firms_tickers[['nger_name', 'morningstar_name', 'match_score', 'ticker','matched']], on = ['nger_name'], how = 'left')\n",
    "nger_data_matched = nger_data_matched.dropna(axis=0, how= 'any', subset=['matched'])\n",
    "print(list(nger_data_matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "nger_data_matched = nger_data_matched.reindex(columns=['year', 'nger_name', 'morningstar_name', 'ticker', 'match_score', 'matched', 'scope1', 'scope2', 'energy_consumption', 'total_emissions'])\n",
    "nger_data_matched = nger_data_matched.reset_index(drop=True)\n",
    "\n",
    "\"Save Matched NGER Data\"\n",
    "output_filename = 'nger_data_matched.csv'\n",
    "outputname = output_path + output_filename\n",
    "nger_data_matched.to_csv(outputname, mode='w', index=False)\n",
    "print(\"Exported File: \" + outputname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e49b3",
   "metadata": {},
   "source": [
    "# Display Matched Firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0add8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Matched Firms:')\n",
    "print(len(matched_firms_tickers))\n",
    "with pd.option_context('display.max_rows', 100, 'display.max_columns', None):\n",
    "    display(matched_firms_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Notebook Finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
